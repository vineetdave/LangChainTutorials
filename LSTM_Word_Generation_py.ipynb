{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vineetdave/LangChainTutorials/blob/main/LSTM_Word_Generation_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Import Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense  # <-- We've replaced SimpleRNN with LSTM\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=Warning)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "X5jG0dw68MDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Cell 2: Define Sample Data\n",
        "# We can use the same data as before.\n",
        "data = \"\"\"\n",
        "Once upon a time in a land far away, there lived a brave knight.\n",
        "This knight was known for his courage and his kindness.\n",
        "One day, the king asked the knight to save the princess from a dragon.\n",
        "The knight accepted the challenge and rode his horse to the dragon's lair.\n",
        "The brave knight fought the dragon and saved the princess.\n",
        "They returned to the castle and lived happily ever after.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Data loaded.\")"
      ],
      "metadata": {
        "id": "MYh03Ixz8NFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02139c02-0a5c-427d-bc70-4f25ab514636"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Cell 3: Tokenize the Text\n",
        "# This step is exactly the same as before.\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "encoded_text = tokenizer.texts_to_sequences([data])[0]\n",
        "\n",
        "print(f\"Total unique words (vocab size): {vocab_size}\")"
      ],
      "metadata": {
        "id": "k_OGa4Hh8R08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2865f2b-3410-4022-badb-eb90b0e6d78b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words (vocab size): 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Cell 4: Create Input Sequences and Targets\n",
        "# This step is also exactly the same.\n",
        "sequences = []\n",
        "seq_length = 5  # The model will read 5 words to predict the 6th\n",
        "\n",
        "for i in range(seq_length, len(encoded_text)):\n",
        "    seq = encoded_text[i-seq_length:i]\n",
        "    label = encoded_text[i]\n",
        "    sequences.append((seq, label))\n",
        "\n",
        "print(f\"Total number of sequences created: {len(sequences)}\")"
      ],
      "metadata": {
        "id": "MIFqN7jq8X7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36eb82a6-c5ee-41c4-be34-0c3011820e46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of sequences created: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Cell 5: Prepare Data for Keras\n",
        "# This is also identical to the previous script.\n",
        "X, y = zip(*sequences)\n",
        "X = np.array(X)\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "print(f\"Shape of X (inputs): {X.shape}\")\n",
        "print(f\"Shape of y (targets): {y.shape}\")"
      ],
      "metadata": {
        "id": "0fyjRHeb8aq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbdbbcc-bd65-4b2d-ef76-95b61080b414"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X (inputs): (66, 5)\n",
            "Shape of y (targets): (66, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Cell 6: Define the LSTM Model Architecture\n",
        "# This is the main change. We are swapping SimpleRNN for LSTM.\n",
        "\n",
        "embedding_dim = 50\n",
        "lstm_units = 100  # We'll use 100 memory units, just like before\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding Layer (same as before)\n",
        "model.add(Embedding(input_dim=vocab_size,\n",
        "                    output_dim=embedding_dim,\n",
        "                    input_length=seq_length))\n",
        "\n",
        "# *** THE KEY CHANGE IS HERE ***\n",
        "# We use an LSTM layer instead of a SimpleRNN layer.\n",
        "# The LSTM is much better at remembering long-term patterns\n",
        "# and avoids the vanishing gradient problem.\n",
        "model.add(LSTM(lstm_units))\n",
        "# Note: The default activation for LSTM is 'tanh', which is standard.\n",
        "\n",
        "# Output Layer (same as before)\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "PByB70cQ8gGs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8037239f-7d65-422f-ce5a-299034c9a60d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Cell 7: Compile and Train the Model\n",
        "# The compilation and training process is exactly the same.\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Starting LSTM model training...\")\n",
        "# With a more complex model like LSTM, you may need even more epochs\n",
        "# to get good results.\n",
        "model.fit(X, y, epochs=100, batch_size=5, verbose=2)\n",
        "print(\"Model training complete.\")\n"
      ],
      "metadata": {
        "id": "3gYDGOG685Dt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624aa368-26da-4ab8-96ce-743570367ada"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting LSTM model training...\n",
            "Epoch 1/100\n",
            "14/14 - 3s - 205ms/step - accuracy: 0.0758 - loss: 3.8054\n",
            "Epoch 2/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.1515 - loss: 3.7772\n",
            "Epoch 3/100\n",
            "14/14 - 0s - 13ms/step - accuracy: 0.1515 - loss: 3.7350\n",
            "Epoch 4/100\n",
            "14/14 - 0s - 19ms/step - accuracy: 0.1515 - loss: 3.6325\n",
            "Epoch 5/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.1515 - loss: 3.4431\n",
            "Epoch 6/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.1515 - loss: 3.3185\n",
            "Epoch 7/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.1515 - loss: 3.2601\n",
            "Epoch 8/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.1667 - loss: 3.1619\n",
            "Epoch 9/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.1667 - loss: 3.1245\n",
            "Epoch 10/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.1818 - loss: 2.9773\n",
            "Epoch 11/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.2121 - loss: 2.8511\n",
            "Epoch 12/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.2273 - loss: 2.7324\n",
            "Epoch 13/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.2424 - loss: 2.6146\n",
            "Epoch 14/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.3030 - loss: 2.4872\n",
            "Epoch 15/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.2727 - loss: 2.3793\n",
            "Epoch 16/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.3333 - loss: 2.2735\n",
            "Epoch 17/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.3182 - loss: 2.1653\n",
            "Epoch 18/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.3485 - loss: 2.0451\n",
            "Epoch 19/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.3939 - loss: 1.9447\n",
            "Epoch 20/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.4242 - loss: 1.8280\n",
            "Epoch 21/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.4091 - loss: 1.7377\n",
            "Epoch 22/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 0.5152 - loss: 1.6255\n",
            "Epoch 23/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 0.5606 - loss: 1.5131\n",
            "Epoch 24/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.5455 - loss: 1.4272\n",
            "Epoch 25/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.6364 - loss: 1.3281\n",
            "Epoch 26/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.6667 - loss: 1.2298\n",
            "Epoch 27/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.6667 - loss: 1.1599\n",
            "Epoch 28/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.7576 - loss: 1.0900\n",
            "Epoch 29/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.8636 - loss: 0.9883\n",
            "Epoch 30/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.8939 - loss: 0.9070\n",
            "Epoch 31/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 0.8939 - loss: 0.8312\n",
            "Epoch 32/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 0.9091 - loss: 0.7510\n",
            "Epoch 33/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 0.8939 - loss: 0.6885\n",
            "Epoch 34/100\n",
            "14/14 - 0s - 11ms/step - accuracy: 0.9394 - loss: 0.6342\n",
            "Epoch 35/100\n",
            "14/14 - 0s - 15ms/step - accuracy: 0.9697 - loss: 0.5781\n",
            "Epoch 36/100\n",
            "14/14 - 0s - 14ms/step - accuracy: 0.9697 - loss: 0.5135\n",
            "Epoch 37/100\n",
            "14/14 - 0s - 14ms/step - accuracy: 0.9545 - loss: 0.4694\n",
            "Epoch 38/100\n",
            "14/14 - 0s - 14ms/step - accuracy: 0.9697 - loss: 0.4312\n",
            "Epoch 39/100\n",
            "14/14 - 0s - 22ms/step - accuracy: 0.9545 - loss: 0.3924\n",
            "Epoch 40/100\n",
            "14/14 - 0s - 21ms/step - accuracy: 0.9848 - loss: 0.3584\n",
            "Epoch 41/100\n",
            "14/14 - 0s - 22ms/step - accuracy: 0.9848 - loss: 0.3281\n",
            "Epoch 42/100\n",
            "14/14 - 0s - 14ms/step - accuracy: 0.9848 - loss: 0.3067\n",
            "Epoch 43/100\n",
            "14/14 - 0s - 15ms/step - accuracy: 1.0000 - loss: 0.2707\n",
            "Epoch 44/100\n",
            "14/14 - 0s - 14ms/step - accuracy: 1.0000 - loss: 0.2495\n",
            "Epoch 45/100\n",
            "14/14 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.2281\n",
            "Epoch 46/100\n",
            "14/14 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.2113\n",
            "Epoch 47/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.1888\n",
            "Epoch 48/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.1733\n",
            "Epoch 49/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.1608\n",
            "Epoch 50/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.1509\n",
            "Epoch 51/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.1419\n",
            "Epoch 52/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.1336\n",
            "Epoch 53/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.1226\n",
            "Epoch 54/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.1158\n",
            "Epoch 55/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.1122\n",
            "Epoch 56/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.1108\n",
            "Epoch 57/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0993\n",
            "Epoch 58/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0964\n",
            "Epoch 59/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0903\n",
            "Epoch 60/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0825\n",
            "Epoch 61/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0784\n",
            "Epoch 62/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0747\n",
            "Epoch 63/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0706\n",
            "Epoch 64/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0676\n",
            "Epoch 65/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0644\n",
            "Epoch 66/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0620\n",
            "Epoch 67/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0593\n",
            "Epoch 68/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0572\n",
            "Epoch 69/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0547\n",
            "Epoch 70/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0531\n",
            "Epoch 71/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0510\n",
            "Epoch 72/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0491\n",
            "Epoch 73/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0474\n",
            "Epoch 74/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0456\n",
            "Epoch 75/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0441\n",
            "Epoch 76/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0427\n",
            "Epoch 77/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0413\n",
            "Epoch 78/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0401\n",
            "Epoch 79/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0390\n",
            "Epoch 80/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0378\n",
            "Epoch 81/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0366\n",
            "Epoch 82/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0353\n",
            "Epoch 83/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0347\n",
            "Epoch 84/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0335\n",
            "Epoch 85/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0326\n",
            "Epoch 86/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0316\n",
            "Epoch 87/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0309\n",
            "Epoch 88/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0299\n",
            "Epoch 89/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0293\n",
            "Epoch 90/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0284\n",
            "Epoch 91/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0276\n",
            "Epoch 92/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0270\n",
            "Epoch 93/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0263\n",
            "Epoch 94/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0258\n",
            "Epoch 95/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0250\n",
            "Epoch 96/100\n",
            "14/14 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0244\n",
            "Epoch 97/100\n",
            "14/14 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0238\n",
            "Epoch 98/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0232\n",
            "Epoch 99/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0227\n",
            "Epoch 100/100\n",
            "14/14 - 0s - 8ms/step - accuracy: 1.0000 - loss: 0.0222\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Cell 8: Define the Text Generation Function\n",
        "# This function is 100% identical to the one from the SimpleRNN script.\n",
        "# Because the model's input and output shapes are the same,\n",
        "# we don't need to change anything.\n",
        "\n",
        "def generate_text(seed_text, n_words):\n",
        "    generated_text = seed_text\n",
        "    current_text = seed_text\n",
        "\n",
        "    int_to_word = {v: k for k, v in tokenizer.word_index.items()}\n",
        "\n",
        "    for _ in range(n_words):\n",
        "        encoded = tokenizer.texts_to_sequences([current_text])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\n",
        "        y_pred_probs = model.predict(encoded, verbose=0)[0]\n",
        "        y_pred_index = np.argmax(y_pred_probs)\n",
        "\n",
        "        out_word = int_to_word.get(y_pred_index, '?')\n",
        "\n",
        "        current_text += \" \" + out_word\n",
        "        generated_text += \" \" + out_word\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "print(\"Text generation function defined.\")"
      ],
      "metadata": {
        "id": "rirO5LNn885e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e19f93-6364-4137-aee4-c8e0bc8a1582"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text generation function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# Cell 9: Generate New Text\n",
        "# Now we can test our new LSTM-powered model.\n",
        "\n",
        "seed_text = \"the knight went to the\"\n",
        "generated = generate_text(seed_text, 20) # Generate 20 new words\n",
        "\n",
        "print(\"\\n--- SEED TEXT ---\")\n",
        "print(seed_text)\n",
        "print(\"\\n--- GENERATED TEXT (from LSTM) ---\")\n",
        "print(generated)"
      ],
      "metadata": {
        "id": "jFhR-jR38_1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b935ec07-dcbb-4c39-ed9a-9e8e3d1bbc47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- SEED TEXT ---\n",
            "the knight went to the\n",
            "\n",
            "--- GENERATED TEXT (from LSTM) ---\n",
            "the knight went to the princess princess from brave the knight knight was and and rode rode his the the dragon's dragon's lair the knight\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}